{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b772f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path, PurePath\n",
    "import numpy as np\n",
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KDTree\n",
    "from umap import umap_\n",
    "import random\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.multiprocessing as mp\n",
    "import torch as torch\n",
    "from torch import nn\n",
    "from catalyst.src.ml.nn.models.alignn import Encoder, Processor, Decoder,PositiveScalarsDecoder, ALIGNN\n",
    "from catalyst.src.ml.testing import test_intepretable, test_non_intepretable\n",
    "from catalyst.src.characterization.graph_order_parameter.gop import GOP\n",
    "from catalyst.src.ml.training import run_training, run_pre_training\n",
    "from catalyst.src.characterization.sodas.model.sodas import SODAS\n",
    "from catalyst.src.ml.utils.distributed import cuda_destroy\n",
    "from catalyst.src.graph.graph import Generic_Graph_Data\n",
    "import catalyst.src.utilities.sampling as sampling\n",
    "from catalyst.src.ml.ml import ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b58f103",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ML parameter INITIALIZATION\n",
    "'''\n",
    "ml_parameters = dict(\n",
    "                    device_dict = dict(\n",
    "                        world_size=1,\n",
    "                        device='cuda',\n",
    "                        run_ddp=False,\n",
    "                        pin_memory=False,\n",
    "                    ),\n",
    "                    io_dict = dict(\n",
    "                        main_path=str(Path(__file__).parent),\n",
    "                        loaded_model_name=None,\n",
    "                        data_dir=None,\n",
    "                        model_dir=None,\n",
    "                        results_dir=None,\n",
    "                        samples_dir=None,\n",
    "                        projection_dir=None,\n",
    "                        remove_old_model=True,\n",
    "                        write_indv_pred=False,\n",
    "                    ),\n",
    "                    sampling_dict = dict(\n",
    "                            sampling_types=['kmeans','kmeans','kmeans'],\n",
    "                            split=[0.1,0.2,0.75],\n",
    "                            sampling_seed=112358,\n",
    "                            params_groups = [{\n",
    "                                'clusters':5,\n",
    "                            },{\n",
    "                                'clusters':5,\n",
    "                            },{\n",
    "                                'clusters':5,\n",
    "                            }]\n",
    "                    ),\n",
    "                    loader_dict=dict(\n",
    "                        shuffle_loader=True,\n",
    "                        batch_size=[100,100,100],\n",
    "                        num_workers=0,\n",
    "                        shuffle_steps=10\n",
    "                    ),\n",
    "                    characterization_dict = dict(\n",
    "                        run_characterization=True,\n",
    "                        model = SODAS(mod=ALIGNN(\n",
    "                            encoder=Encoder(num_species=1, cutoff=4.0, dim=100, act_func=nn.SiLU()),\n",
    "                            processor=Processor(num_convs=5, dim=100),\n",
    "                            decoder=Decoder(in_dim=100, out_dim=10, act_func=nn.SiLU())\n",
    "                        ),\n",
    "                        ls_mod=umap_.UMAP(n_neighbors=15, min_dist=0.5, n_components=2)\n",
    "                        ),\n",
    "                    ),\n",
    "                    model_dict = dict(\n",
    "                        n_models=1,\n",
    "                        num_epochs=[10,10],\n",
    "                        train_tolerance=1.0,\n",
    "                        max_deltas=4,\n",
    "                        loss_func=torch.nn.MSELoss(),\n",
    "                        accumulate_loss=['sum', 'exact', 'exact'],\n",
    "                        model=ALIGNN(\n",
    "                            encoder=Encoder(num_species=1, cutoff=4.0, dim=100, act_func=nn.SiLU()),\n",
    "                            processor=Processor(num_convs=5, dim=100, conv_type='mesh'),\n",
    "                            decoder=PositiveScalarsDecoder(dim=100),\n",
    "                        ),\n",
    "                        interpretable=False,\n",
    "                        pre_training=True,\n",
    "                        restart_training=False,\n",
    "                        optimizer_params=dict(\n",
    "                            dynamic_lr=False,\n",
    "                            optimizer='AdamW',\n",
    "                            params_group={\n",
    "                                'lr': 0.001\n",
    "                            }\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "ml = ML()\n",
    "ml.set_params(ml_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835eaa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DATA INITIALIZATION AND GRAPH CONSTRUCTION\n",
    "'''\n",
    "ml.parameters['io_dict']['data_dir'] = os.path.join(ml.parameters['io_dict']['main_path'],'data')\n",
    "if os.path.isdir(ml.parameters['io_dict']['data_dir']):\n",
    "    shutil.rmtree(ml.parameters['io_dict']['data_dir'])\n",
    "os.mkdir(ml.parameters['io_dict']['data_dir'])\n",
    "n_data = 1000\n",
    "n_nodes = 1000\n",
    "n_dim = 10\n",
    "k = 5 # number of neighbors per graph nodes\n",
    "dataset = []\n",
    "for ds in range(n_data):\n",
    "    if ds % 500 == 0:\n",
    "        print('Generating graph ',ds)\n",
    "    data = np.random.random((n_nodes,n_dim))\n",
    "    tree = KDTree(data,metric='minkowski',leaf_size=2)\n",
    "    dist, ind = tree.query(data,k=k+1) # k+1 due to self-interaction\n",
    "    g_nodes = []\n",
    "    g_edge_index = [[],[]]\n",
    "    a_nodes = []\n",
    "    for i, x in enumerate(ind):\n",
    "        g_nodes.append([1])\n",
    "        for j, xx in enumerate(ind[i]):\n",
    "            if j > 0:\n",
    "                g_edge_index[0].append(x[0])\n",
    "                g_edge_index[1].append(xx)\n",
    "                a_nodes.append(dist[i][j])\n",
    "    g_edge_index = np.array(g_edge_index)\n",
    "    graph = Generic_Graph_Data(\n",
    "        node_G=torch.tensor(g_nodes, dtype=torch.float),\n",
    "        edge_index_G=torch.tensor(g_edge_index, dtype=torch.long),\n",
    "        node_A=torch.tensor(a_nodes, dtype=torch.float)\n",
    "    )\n",
    "    graph.generate_gid()\n",
    "    graph.y = torch.tensor(random.uniform(0,1))\n",
    "    torch.save(graph, os.path.join(os.path.join(ml.parameters['io_dict']['main_path'],ml.parameters['io_dict']['data_dir']), graph.gid + '.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d7df2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PROJECT DATA\n",
    "'''\n",
    "fig, ax = plt.subplots(nrows=1, ncols=4,sharex=True,sharey=True)\n",
    "graph_data = [torch.load(file_name) for file_name in glob.glob(os.path.join(ml.parameters['io_dict']['data_dir'],'*'))]\n",
    "if ml.parameters['characterization_dict']['run_characterization']:\n",
    "    # read data and perform projections\n",
    "    print('Performing graph projections...')\n",
    "    ml.parameters['io_dict']['projection_dir'] = os.path.join(ml.parameters['io_dict']['main_path'],'projections')\n",
    "    if os.path.isdir(ml.parameters['io_dict']['projection_dir']):\n",
    "        shutil.rmtree(ml.parameters['io_dict']['projection_dir'])\n",
    "    os.mkdir(ml.parameters['io_dict']['projection_dir'])\n",
    "    ml.parameters['io_dict']['samples_dir'] = os.path.join(ml_parameters['io_dict']['main_path'], 'samples')\n",
    "    if os.path.isdir(ml.parameters['io_dict']['samples_dir']):\n",
    "        shutil.rmtree(ml.parameters['io_dict']['samples_dir'])\n",
    "    os.mkdir(ml.parameters['io_dict']['samples_dir'])\n",
    "    projected_data = None\n",
    "    encoded_data = []\n",
    "    gids = []\n",
    "    follow_batch = ['node_G', 'node_A']\n",
    "    for data in graph_data:\n",
    "        gids.append(data.gid)\n",
    "        loader = DataLoader([data], batch_size=1, shuffle=False, follow_batch=follow_batch,\n",
    "                            num_workers=ml_parameters['loader_dict']['num_workers'])\n",
    "        encoded_data.append(ml.parameters['characterization_dict']['model'].generate_gnn_latent_space(loader=loader,\n",
    "                device=ml.parameters['device_dict']['device'])[0])\n",
    "    encoded_data = np.array(encoded_data)\n",
    "    ml.parameters['characterization_dict']['model'].fit_preprocess(data=encoded_data)\n",
    "    ml.parameters['characterization_dict']['model'].fit_dim_red(data=encoded_data)\n",
    "    projected_data = ml.parameters['characterization_dict']['model'].project_data(data=encoded_data)\n",
    "    stored_projections = dict(\n",
    "        projections=projected_data,\n",
    "        gids=gids\n",
    "    )\n",
    "    np.save(os.path.join(ml.parameters['io_dict']['projection_dir'], 'projection_data.npy'), stored_projections)\n",
    "    ax[0].plot(projected_data[:, 0], projected_data[:, 1], linestyle='', marker='o', color='w', markeredgecolor='k')\n",
    "    ax[0].set_title('All data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea906e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "SAMPLE DATA\n",
    "'''\n",
    "#start sampling\n",
    "rng = np.random.default_rng(seed=ml.parameters['sampling_dict']['sampling_seed'])\n",
    "# REMOVE TEST DATA\n",
    "test_idx, nontest_idx = sampling.run_sampling(projected_data,\n",
    "                                                  sampling_type=ml.parameters['sampling_dict']['sampling_types'][0],\n",
    "                                                  split=ml.parameters['sampling_dict']['split'][0], rng=rng,\n",
    "                                                  params_group=ml.parameters['sampling_dict']['params_groups'][0])\n",
    "stored_test_data = dict(\n",
    "        projections=[projected_data[index] for index in test_idx],\n",
    "        gids=[graph_data[index].gid for index in test_idx]\n",
    ")\n",
    "projected_data = [projected_data[index] for index in nontest_idx]\n",
    "graph_data = [graph_data[index] for index in nontest_idx]\n",
    "np.save(os.path.join(ml.parameters['io_dict']['samples_dir'], 'test_data.npy'), stored_test_data)\n",
    "ax[1].plot(np.array(stored_test_data['projections'])[:, 0], np.array(stored_test_data['projections'])[:, 1], linestyle='', marker='o', color='r', markeredgecolor='k')\n",
    "ax[1].set_title('Test data')\n",
    "# REMOVE PRETRAIN DATA\n",
    "if ml.parameters['model_dict']['pre_training']:\n",
    "    pretraining_data = None\n",
    "    # perform pretraining\n",
    "    ml.parameters['io_dict']['pretrain_dir'] = os.path.join(ml.parameters['io_dict']['samples_dir'],'pretrain')\n",
    "    if os.path.isdir(ml.parameters['io_dict']['pretrain_dir']):\n",
    "        shutil.rmtree(ml.parameters['io_dict']['pretrain_dir'])\n",
    "    os.mkdir(ml.parameters['io_dict']['pretrain_dir'])\n",
    "    # remove pretrain data\n",
    "    pretrain_idx, nonpretrain_idx = sampling.run_sampling(projected_data, sampling_type=\n",
    "    ml.parameters['sampling_dict']['sampling_types'][1], split=ml.parameters['sampling_dict']['split'][1], rng=rng,\n",
    "                                                              params_group=ml.parameters['sampling_dict']['params_groups'][1])\n",
    "    stored_pretrain_data = dict(\n",
    "            training_projections=[projected_data[index] for index in pretrain_idx],\n",
    "            validation_projections=None,\n",
    "            training=[graph_data[index].gid for index in pretrain_idx],\n",
    "            validation=None\n",
    "    )\n",
    "    projected_data = [projected_data[index] for index in nonpretrain_idx]\n",
    "    graph_data = [graph_data[index] for index in nonpretrain_idx]\n",
    "    np.save(os.path.join(ml.parameters['io_dict']['pretrain_dir'], 'train_valid_split.npy'), stored_pretrain_data,\n",
    "                fix_imports=False)\n",
    "    ax[2].plot(np.array(stored_pretrain_data['training_projections'])[:, 0], np.array(stored_pretrain_data['training_projections'])[:, 1], linestyle='',\n",
    "                   marker='o', color='c', markeredgecolor='k')\n",
    "    ax[2].set_title('Pretrain data')\n",
    "# REMOVE TRAINING DATA\n",
    "ml.parameters['io_dict']['model_dir'] = os.path.join(ml.parameters['io_dict']['samples_dir'], 'model_samples')\n",
    "if os.path.isdir(ml.parameters['io_dict']['model_dir']):\n",
    "    shutil.rmtree(ml.parameters['io_dict']['model_dir'])\n",
    "os.mkdir(ml.parameters['io_dict']['model_dir'])\n",
    "for iteration in range(ml.parameters['model_dict']['n_models']):\n",
    "    ml.parameters['io_dict']['model_dir'] = None\n",
    "    del ml.parameters['io_dict']['model_dir']\n",
    "    ml.parameters['io_dict']['model_dir'] = os.path.join(ml.parameters['io_dict']['samples_dir'], 'model_samples', str(iteration))\n",
    "    if os.path.isdir(ml.parameters['io_dict']['model_dir']):\n",
    "        shutil.rmtree(ml.parameters['io_dict']['model_dir'])\n",
    "    os.makedirs(ml.parameters['io_dict']['model_dir'], exist_ok=True)\n",
    "    # sample data and train model\n",
    "    train_idx, valid_idx = sampling.run_sampling(projected_data,\n",
    "                                                     sampling_type=ml.parameters['sampling_dict']['sampling_types'][2],\n",
    "                                                     split=ml.parameters['sampling_dict']['split'][2], rng=rng,\n",
    "                                                     params_group=ml.parameters['sampling_dict']['params_groups'][2])\n",
    "    train_data = [graph_data[index].gid for index in train_idx]\n",
    "    valid_data = [graph_data[index].gid for index in valid_idx]\n",
    "    print('Using the remaining ', len(valid_data), ' for validation')\n",
    "    partitioned_data = dict(\n",
    "            training_projections=[projected_data[index] for index in train_idx],\n",
    "            validation_projections=[projected_data[index] for index in valid_idx],\n",
    "            training=train_data,\n",
    "            validation=valid_data\n",
    "    )\n",
    "    np.save(os.path.join(ml.parameters['io_dict']['model_dir'], 'train_valid_split.npy'), partitioned_data)\n",
    "    ax[3].plot(np.array(partitioned_data ['training_projections'])[:, 0], np.array(partitioned_data['training_projections'])[:, 1],\n",
    "                   linestyle='',marker='o', color='y', markeredgecolor='k')\n",
    "    ax[3].set_title('Training data')\n",
    "del graph_data\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3719ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PERFORM MODEL TRAINING\n",
    "'''\n",
    "# create model directories\n",
    "ml.parameters['io_dict']['model_dir'] = None\n",
    "ml.parameters['io_dict']['samples_dir'] = None\n",
    "del ml.parameters['io_dict']['model_dir']\n",
    "del ml.parameters['io_dict']['samples_dir']\n",
    "ml.parameters['io_dict']['samples_dir'] = [os.path.join(ml_parameters['io_dict']['main_path'], 'samples','pretrain'),\n",
    "                                           os.path.join(ml_parameters['io_dict']['main_path'], 'samples','model_samples')]\n",
    "if ml_parameters['model_dict']['restart_training']:\n",
    "    ml.parameters['io_dict']['model_dir'] = os.path.join(ml_parameters['io_dict']['main_path'], 'models_restart')\n",
    "else:\n",
    "    ml.parameters['io_dict']['model_dir'] = os.path.join(ml_parameters['io_dict']['main_path'], 'models')\n",
    "if os.path.isdir(ml.parameters['io_dict']['model_dir']):\n",
    "    shutil.rmtree(ml.parameters['io_dict']['model_dir'])\n",
    "os.mkdir(ml.parameters['io_dict']['model_dir'])\n",
    "if ml.parameters['model_dict']['pre_training']:\n",
    "    print('Performing pretraining...')\n",
    "    run_pre_training(rank=0, ml=ml)\n",
    "for iteration in range(ml.parameters['model_dict']['n_models']):\n",
    "    print('Performing training on model ', iteration)\n",
    "    run_training(rank=0, iteration=iteration, ml=ml)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2,sharex=True,sharey=False)\n",
    "ax[0].set_title('Pretraining loss')\n",
    "ax[1].set_title('Training loss')\n",
    "fname = os.path.join(ml_parameters['io_dict']['main_path'],'models','pretraining','loss.data')\n",
    "loss = []\n",
    "of = open(fname,'r')\n",
    "for lines in of:\n",
    "    line = lines.split()\n",
    "    if len(line) == 1:\n",
    "        loss.append(float(line[0]))\n",
    "of.close()\n",
    "x=np.linspace(1,len(loss),len(loss))\n",
    "ax[0].plot(x,loss,color='b',marker='o')\n",
    "fname = os.path.join(ml_parameters['io_dict']['main_path'],'models','training','0','loss.data')\n",
    "loss = [[],[]]\n",
    "of = open(fname,'r')\n",
    "for lines in of:\n",
    "    line = lines.split()\n",
    "    if len(line) == 2:\n",
    "        loss[0].append(float(line[0]))\n",
    "        loss[1].append(float(line[1]))\n",
    "of.close()\n",
    "x=np.linspace(1,len(loss[0]),len(loss[0]))\n",
    "ax[1].plot(x,loss[0],color='b',marker='o',label='Training loss')\n",
    "ax[1].plot(x,loss[1],color='r',marker='o',label='Validation loss')\n",
    "ax[1].legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8be4454",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TEST MODEL\n",
    "'''\n",
    "ml.parameters['io_dict']['write_indv_pred'] = True\n",
    "ml.parameters['io_dict']['results_dir'] = os.path.join(ml_parameters['io_dict']['main_path'],'testing')\n",
    "if os.path.isdir(ml.parameters['io_dict']['results_dir']):\n",
    "    shutil.rmtree(ml.parameters['io_dict']['results_dir'])\n",
    "os.mkdir(ml.parameters['io_dict']['results_dir'])\n",
    "model_data = torch.load(glob.glob(os.path.join(ml.parameters['io_dict']['model_dir'],'model*'))[0])\n",
    "print('Testing model ' + PurePath(glob.glob(os.path.join(ml.parameters['io_dict']['model_dir'],'model*'))[0]).parts[-1])\n",
    "ml.set_model()\n",
    "ml.model.load_state_dict(model_data['model'])\n",
    "ml.model.to(ml.parameters['device_dict']['device'])\n",
    "graph_data = [torch.load(file_name) for file_name in glob.glob(os.path.join(ml.parameters['io_dict']['data_dir'],'*'))]\n",
    "follow_batch = ['node_G', 'node_A', 'edge_A'] if hasattr(graph_data[0], 'edge_A') else ['node_G', 'node_A']\n",
    "loader = DataLoader(graph_data, batch_size=1, shuffle=False, follow_batch=follow_batch)\n",
    "print(f'Number of test graphs: {len(loader.dataset)}')\n",
    "if ml.parameters['model_dict']['interpretable']:\n",
    "    loss = test_intepretable(loader=loader,model=ml.model,parameters=ml.parameters)\n",
    "else:\n",
    "    loss = test_non_intepretable(loader=loader, model=ml.model, parameters=ml.parameters)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1,sharex=True,sharey=False)\n",
    "fname = os.path.join(ml_parameters['io_dict']['results_dir'],'all_indv_pred.data')\n",
    "pred = [[],[]]\n",
    "of = open(fname,'r')\n",
    "for lines in of:\n",
    "    line = lines.split()\n",
    "    if len(line) == 2:\n",
    "        pred[0].append(float(line[0]))\n",
    "        pred[1].append(float(line[1]))\n",
    "of.close()\n",
    "ax.plot(pred[0],pred[0],linestyle='-',color='r')\n",
    "ax.plot(pred[0],pred[1],linestyle='',color='dodgerblue',marker='o',markeredgecolor='k')\n",
    "ax.set_xlabel('True values')\n",
    "ax.set_ylabel('ML values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1f2905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998801cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280a4431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245db118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1157c698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd0401a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf62996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a25747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296cf8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ced62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e6b46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83797b6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
